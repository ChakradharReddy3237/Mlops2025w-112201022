{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fc442234",
      "metadata": {
        "id": "fc442234"
      },
      "source": [
        "# CIFAR-100: Full Lab ‚Äî Account setup, Train ‚Üí W&B ‚Üí Deploy on Hugging Face Spaces\n",
        "**Colab-ready hands-on lab notebook**\n",
        "\n",
        "This notebook combines:\n",
        "- Step-by-step instructions to create a **Hugging Face** account and **access token**,\n",
        "- Secure token input in Colab using `getpass` (token is not printed),\n",
        "- **W&B** authentication,\n",
        "- Training a `resnet18` on **CIFAR-100**, logging to W&B and saving model as an artifact,\n",
        "- A Gradio app (`app.py`) that downloads the model artifact from W&B at startup,\n",
        "- A script to create & push a **Hugging Face Space** (Gradio) from Colab using `huggingface_hub`.\n",
        "\n",
        "**Security note:** Never commit your tokens/API keys to public repos. Use Colab `getpass` to keep tokens secret and use HF Space Secrets for W&B keys.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "wsHTuNBK6hPm",
      "metadata": {
        "id": "wsHTuNBK6hPm"
      },
      "outputs": [],
      "source": [
        "# DO NOT hardcode API keys! Use environment variables or getpass instead.\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Option 1: Load from environment (recommended)\n",
        "wandb_key = os.environ.get('WANDB_API_KEY')\n",
        "if not wandb_key:\n",
        "    # Option 2: Prompt securely if not set\n",
        "    wandb_key = getpass('Enter W&B API key: ')\n",
        "    os.environ['WANDB_API_KEY'] = wandb_key\n",
        "else:\n",
        "    print(\"‚úÖ W&B API key loaded from environment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "JHWXyy1W8lPj",
      "metadata": {
        "id": "JHWXyy1W8lPj"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "os.environ['HF_USER'] = input('Enter HF username: ')\n",
        "os.environ['SPACE_NAME'] = input('Enter space name: ')\n",
        "os.environ['HF_TOKEN'] = getpass('Enter HF token: ') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f4ac50e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4ac50e3",
        "outputId": "d66dad02-9d9f-486e-cc2a-607d202cf4ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---- Environment Validation ----\n",
            "GPU available: False\n",
            "HF_TOKEN:  SET\n",
            "HF_USER:  SET\n",
            "SPACE_NAME:  SET\n",
            "WANDB_API_KEY:  SET\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/chakri/Documents/Projects/Chicken-Disease-Classification/chicken/lib/python3.12/site-packages/torch/cuda/__init__.py:182: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
            "  return torch._C._cuda_getDeviceCount() > 0\n",
            "/home/chakri/Documents/Projects/Chicken-Disease-Classification/chicken/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/home/chakri/Documents/Projects/Chicken-Disease-Classification/chicken/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dependencies:  wandb, gradio, huggingface_hub imported successfully\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "#@title üîç Environment Validation (run before starting lab)\n",
        "import torch, os\n",
        "\n",
        "print(\"---- Environment Validation ----\")\n",
        "\n",
        "# Check GPU availability\n",
        "print(\"GPU available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# Check required env vars\n",
        "for var in [\"HF_TOKEN\", \"HF_USER\", \"SPACE_NAME\"]:\n",
        "    val = os.environ.get(var)\n",
        "    print(f\"{var}:\", \" SET\" if val else \"NOT SET\")\n",
        "\n",
        "# Check if W&B API key configured (login handled separately)\n",
        "wandb_key = os.environ.get(\"WANDB_API_KEY\")\n",
        "print(\"WANDB_API_KEY:\", \" SET\" if wandb_key else \"‚ö†Ô∏è Not set (you'll log in interactively)\")\n",
        "\n",
        "# Check if dependencies installed\n",
        "try:\n",
        "    import wandb, gradio, huggingface_hub\n",
        "    print(\"Dependencies:  wandb, gradio, huggingface_hub imported successfully\")\n",
        "except Exception as e:\n",
        "    print(\"Dependencies: missing - please run install cell first\")\n",
        "    print(e)\n",
        "\n",
        "print(\"---------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fe559f7",
      "metadata": {
        "id": "5fe559f7"
      },
      "outputs": [],
      "source": [
        "#@title 1) Install dependencies (run once)\n",
        "# Installs pytorch (with CUDA if available), W&B, Gradio and HF tooling.\n",
        "!pip install -q torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q wandb gradio huggingface_hub git-lfs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ded0f9e",
      "metadata": {
        "id": "7ded0f9e"
      },
      "source": [
        "## 2) Hugging Face account & token (student instructions)\n",
        "\n",
        "**If you don't have a Hugging Face account:**\n",
        "1. Go to https://huggingface.co and click **Sign up**. Verify email.\n",
        "2. Choose a username (used as `HF_USER`).\n",
        "\n",
        "**Create an Access Token:**\n",
        "1. Go to https://huggingface.co/settings/tokens\n",
        "2. Click **New token**. Name it (e.g., `colab-space-token`) and select scope `repo` (read & write).\n",
        "3. Click **Create** and copy the token now ‚Äî you won't see it again.\n",
        "\n",
        "**Important:** Keep the token secret. Use the next cell to set it securely in Colab (the token will not be printed)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "399c2879",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "399c2879",
        "outputId": "cc3786e0-1c2c-430d-dabf-88e5a6eb2b5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste your Hugging Face token when prompted. It will be hidden.\n"
          ]
        }
      ],
      "source": [
        "#@title 3) Securely set your Hugging Face token, username, and desired Space name\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "print(\"Paste your Hugging Face token when prompted. It will be hidden.\")\n",
        "hf_token = getpass(\"Hugging Face token: \")\n",
        "os.environ['HF_TOKEN'] = hf_token\n",
        "\n",
        "# Edit these values (do NOT put the token here)\n",
        "hf_user = input(\"Enter your Hugging Face username (e.g. 'alice'): \").strip()\n",
        "space_name = input(\"Enter desired Space name (e.g. 'cifar100-demo-space'): \").strip()\n",
        "\n",
        "os.environ['HF_USER'] = hf_user\n",
        "os.environ['SPACE_NAME'] = space_name\n",
        "\n",
        "print(\"HF_TOKEN stored in runtime (hidden). HF_USER and SPACE_NAME saved in environment variables.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a4723f4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4723f4e",
        "outputId": "a813f8dc-8efc-46b1-fae5-2b3f259171d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Follow the prompt to authenticate W&B (this opens an input box).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m112201022\u001b[0m (\u001b[33mir2023\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title 4) Authenticate Weights & Biases (W&B)\n",
        "import wandb\n",
        "print(\"Follow the prompt to authenticate W&B (this opens an input box).\")\n",
        "wandb.login()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "168998a0",
      "metadata": {
        "id": "168998a0"
      },
      "source": [
        "## 5) Create `train.py` ‚Äî training + W&B artifact logging\n",
        "\n",
        "This script trains ResNet18 on CIFAR-100, logs metrics to W&B, and saves the best model as a W&B artifact.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a5635d6e",
      "metadata": {
        "id": "a5635d6e"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat > train.py <<'PY'\n",
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import wandb\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "def parse_args():\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument(\"--project\", type=str, default=\"cifar100-hf-demo\")\n",
        "    p.add_argument(\"--entity\", type=str, default=None)\n",
        "    p.add_argument(\"--epochs\", type=int, default=5)\n",
        "    p.add_argument(\"--batch-size\", type=int, default=128)\n",
        "    p.add_argument(\"--lr\", type=float, default=0.01)\n",
        "    return p.parse_args()\n",
        "\n",
        "def get_dataloaders(batch_size):\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5071, 0.4865, 0.4409),\n",
        "                             (0.2673, 0.2564, 0.2762)),\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5071, 0.4865, 0.4409),\n",
        "                             (0.2673, 0.2564, 0.2762)),\n",
        "    ])\n",
        "    trainset = torchvision.datasets.CIFAR100(root=\"./data\", train=True, download=True, transform=transform_train)\n",
        "    testset  = torchvision.datasets.CIFAR100(root=\"./data\", train=False, download=True, transform=transform_test)\n",
        "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    testloader  = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    return trainloader, testloader\n",
        "\n",
        "def train_one_epoch(model, device, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (inputs, targets) in enumerate(loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    return running_loss / total, 100. * correct / total\n",
        "\n",
        "def evaluate(model, device, loader, criterion):\n",
        "    model.eval()\n",
        "    loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            l = criterion(outputs, targets)\n",
        "            loss += l.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    return loss/total, 100.*correct/total\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "    wandb.init(project=args.project, entity=args.entity, config=vars(args))\n",
        "    cfg = wandb.config\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    trainloader, testloader = get_dataloaders(cfg.batch_size)\n",
        "\n",
        "    model = resnet18(num_classes=100)\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=cfg.lr, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(cfg.epochs):\n",
        "        train_loss, train_acc = train_one_epoch(model, device, trainloader, optimizer, criterion)\n",
        "        test_loss, test_acc = evaluate(model, device, testloader, criterion)\n",
        "        wandb.log({\"epoch\": epoch+1, \"train_loss\": train_loss, \"train_acc\": train_acc,\n",
        "                   \"test_loss\": test_loss, \"test_acc\": test_acc})\n",
        "        print(f\"Epoch {epoch+1}: train_acc={train_acc:.2f} test_acc={test_acc:.2f}\")\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            os.makedirs(\"outputs\", exist_ok=True)\n",
        "            torch.save(model.state_dict(), \"outputs/model.pt\")\n",
        "            # log artifact\n",
        "            artifact = wandb.Artifact(\"resnet18-cifar100\", type=\"model\", metadata={\"test_acc\": best_acc})\n",
        "            artifact.add_file(\"outputs/model.pt\")\n",
        "            wandb.log_artifact(artifact)\n",
        "    print(\"Best test acc:\", best_acc)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "PY\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e2398c34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2398c34",
        "outputId": "e4131cfc-256f-46bc-83ed-288627385f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m112201022\u001b[0m (\u001b[33mir2023\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run cg359xeb (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run cg359xeb (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run cg359xeb (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run cg359xeb (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run cg359xeb (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run cg359xeb (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/chakri/Documents/S-7/MLoPs/Mlops2025w-112201022/CLASS/Week-10/wandb/run-20251022_004042-cg359xeb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwise-sky-18\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ir2023/cifar100-hf-demo\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ir2023/cifar100-hf-demo/runs/cg359xeb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/chakri/Documents/S-7/MLoPs/Mlops2025w-112201022/CLASS/Week-10/wandb/run-20251022_004042-cg359xeb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwise-sky-18\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ir2023/cifar100-hf-demo\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ir2023/cifar100-hf-demo/runs/cg359xeb\u001b[0m\n",
            "/home/chakri/Documents/Projects/Chicken-Disease-Classification/chicken/lib/python3.12/site-packages/torch/cuda/__init__.py:182: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
            "  return torch._C._cuda_getDeviceCount() > 0\n",
            "/home/chakri/Documents/Projects/Chicken-Disease-Classification/chicken/lib/python3.12/site-packages/torch/cuda/__init__.py:182: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
            "  return torch._C._cuda_getDeviceCount() > 0\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 169M/169M [26:13<00:00, 107kB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 169M/169M [26:13<00:00, 107kB/s]\n",
            "Epoch 1: train_acc=10.67 test_acc=16.75\n",
            "Epoch 1: train_acc=10.67 test_acc=16.75\n",
            "Epoch 2: train_acc=19.73 test_acc=23.53\n",
            "Epoch 2: train_acc=19.73 test_acc=23.53\n",
            "Epoch 3: train_acc=25.05 test_acc=29.17\n",
            "Epoch 3: train_acc=25.05 test_acc=29.17\n",
            "Best test acc: 29.17\n",
            "Best test acc: 29.17\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mwise-sky-18\u001b[0m at: \u001b[34mhttps://wandb.ai/ir2023/cifar100-hf-demo/runs/cg359xeb\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251022_004042-cg359xeb/logs\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mwise-sky-18\u001b[0m at: \u001b[34mhttps://wandb.ai/ir2023/cifar100-hf-demo/runs/cg359xeb\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251022_004042-cg359xeb/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@title 6) Run training (edit the --entity to your W&B username/team)\n",
        "# Keep epochs small for demo (e.g., 3-5). Increase for better accuracy.\n",
        "!python train.py --project cifar100-hf-demo --entity 'ir2023' --epochs 3 --batch-size 128\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0db3cd7",
      "metadata": {
        "id": "f0db3cd7"
      },
      "source": [
        "## 7) Download model artifact from W&B (if you didn't run training here)\n",
        "This downloads the latest logged artifact into `outputs/` so the Gradio app can load it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "i_bcgzljuC7y",
      "metadata": {
        "id": "i_bcgzljuC7y"
      },
      "outputs": [],
      "source": [
        "os.environ['WANDB_ENTITY']= \"ir2023\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ed2479c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed2479c6",
        "outputId": "b0681bc8-849d-41d7-b8a7-f9dd6e0f5c96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded artifact to outputs/\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "python - <<'PY'\n",
        "import wandb, os, sys\n",
        "ENTITY = os.environ.get(\"WANDB_ENTITY\") or \"ir2023\"   # <-- edit if not set\n",
        "PROJECT = \"cifar100-hf-demo\"\n",
        "ARTIFACT = \"resnet18-cifar100:latest\"\n",
        "api = wandb.Api()\n",
        "try:\n",
        "    artifact = api.artifact(f\"{ENTITY}/{PROJECT}/{ARTIFACT}\")\n",
        "    artifact.download(root=\"outputs\")\n",
        "    print(\"Downloaded artifact to outputs/\")\n",
        "except Exception as e:\n",
        "    print(\"Failed to download artifact:\", e)\n",
        "    sys.exit(1)\n",
        "PY\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab2f6d6a",
      "metadata": {
        "id": "ab2f6d6a"
      },
      "source": [
        "## 8) Create Gradio app (`app.py`) that downloads the model from W&B at startup\n",
        "\n",
        "This approach avoids committing large model files into the Space repository. The Space must have `WANDB_API_KEY` set as a secret in its settings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "08154d69",
      "metadata": {
        "id": "08154d69"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat > app.py <<'PY'\n",
        "import os, time, io, shutil\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet18\n",
        "import gradio as gr\n",
        "\n",
        "MODEL_PATH = \"outputs/model.pt\"\n",
        "\n",
        "# If model not present, try download via W&B (requires WANDB_API_KEY secret in Space or env)\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    try:\n",
        "        import wandb\n",
        "        wandb_api_key = os.environ.get(\"WANDB_API_KEY\")\n",
        "        if wandb_api_key:\n",
        "            wandb.login(key=wandb_api_key)\n",
        "            api = wandb.Api()\n",
        "            artifact_path = os.environ.get(\"WANDB_ARTIFACT\", \"ir2023/cifar100-hf-demo/resnet18-cifar100:latest\")\n",
        "            print(f\"Downloading artifact: {artifact_path}\")\n",
        "            artifact = api.artifact(artifact_path)\n",
        "            # Remove outputs dir if exists, then download (avoids replace parameter issue)\n",
        "            if os.path.exists(\"outputs\"):\n",
        "                shutil.rmtree(\"outputs\")\n",
        "            artifact.download(root=\"outputs\")\n",
        "            print(\"Downloaded model via W&B artifact successfully.\")\n",
        "        else:\n",
        "            print(\"WANDB_API_KEY not set; cannot download artifact.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading artifact via W&B: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = resnet18(num_classes=100)\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32,32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4865, 0.4409),(0.2673,0.2564,0.2762))\n",
        "])\n",
        "\n",
        "def predict_image(img):\n",
        "    start = time.time()\n",
        "    x = transform(img).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        out = model(x)\n",
        "        probs = torch.nn.functional.softmax(out, dim=1)\n",
        "        conf, idx = probs.max(1)\n",
        "        class_idx = int(idx.item())\n",
        "        conf_val = float(conf.item())\n",
        "    latency = (time.time() - start) * 1000.0\n",
        "    return {\"class_idx\": class_idx, \"confidence\": round(conf_val,4), \"latency_ms\": round(latency,2)}\n",
        "\n",
        "iface = gr.Interface(fn=predict_image, inputs=gr.Image(type=\"pil\"), outputs=\"json\", title=\"CIFAR-100 demo\")\n",
        "if __name__ == \"__main__\":\n",
        "    iface.launch(server_name=\"0.0.0.0\", server_port=7860)\n",
        "PY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "4637e6d4",
      "metadata": {
        "id": "4637e6d4"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat > requirements.txt <<'REQ'\n",
        "torch\n",
        "torchvision\n",
        "gradio\n",
        "Pillow\n",
        "wandb\n",
        "huggingface_hub\n",
        "git-lfs\n",
        "REQ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76dd2e1f",
      "metadata": {
        "id": "76dd2e1f"
      },
      "source": [
        "## 9) Create & push a Hugging Face Space from Colab (uses HF_TOKEN set earlier via getpass)\n",
        "\n",
        "This will:\n",
        "- create the Space repo (if it doesn't exist),\n",
        "- push `app.py` and `requirements.txt` to the Space,\n",
        "- not include the heavy model file (the app downloads it from W&B at runtime).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "8d2ef2d6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Token is valid!\n",
            "Username: Chakradharreddy3237\n",
            "Token type: access_token\n",
            "Token role/scope: fineGrained\n",
            "\n",
            "‚ö†Ô∏è  Unknown permission level: fineGrained\n"
          ]
        }
      ],
      "source": [
        "#@title üîç Check HuggingFace Token Permissions\n",
        "import os\n",
        "from huggingface_hub import HfApi\n",
        "\n",
        "token = os.environ.get(\"HF_TOKEN\")\n",
        "if not token:\n",
        "    print(\"‚ùå HF_TOKEN not set!\")\n",
        "else:\n",
        "    try:\n",
        "        api = HfApi(token=token)\n",
        "        user_info = api.whoami()\n",
        "        print(\"‚úÖ Token is valid!\")\n",
        "        print(f\"Username: {user_info['name']}\")\n",
        "        print(f\"Token type: {user_info.get('auth', {}).get('type', 'Unknown')}\")\n",
        "        \n",
        "        # Check if token has write permissions\n",
        "        scopes = user_info.get('auth', {}).get('accessToken', {}).get('role', 'read')\n",
        "        print(f\"Token role/scope: {scopes}\")\n",
        "        \n",
        "        if scopes == 'read':\n",
        "            print(\"\\n‚ö†Ô∏è  WARNING: Your token has READ-ONLY permissions!\")\n",
        "            print(\"   You CANNOT create Spaces with this token.\")\n",
        "            print(\"\\nüîß To fix:\")\n",
        "            print(\"   1. Go to: https://huggingface.co/settings/tokens\")\n",
        "            print(\"   2. Click 'New token'\")\n",
        "            print(\"   3. Select 'Write' permission (NOT 'Read')\")\n",
        "            print(\"   4. Copy the new token\")\n",
        "            print(\"   5. Re-run Cell 3 and paste the NEW token\")\n",
        "        elif scopes == 'write':\n",
        "            print(\"\\n‚úÖ Token has WRITE permissions - ready to create Spaces!\")\n",
        "        else:\n",
        "            print(f\"\\n‚ö†Ô∏è  Unknown permission level: {scopes}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error checking token: {e}\")\n",
        "        print(\"   The token may be invalid or revoked.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "f0bdfe30",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "HUGGING FACE TOKEN INFORMATION\n",
            "======================================================================\n",
            "Username: Chakradharreddy3237\n",
            "Token type: access_token\n",
            "\n",
            "Token role: fineGrained\n",
            "\n",
            "Permissions:\n",
            "\n",
            "======================================================================\n",
            "‚ùå ERROR: Token does NOT have WRITE permissions!\n",
            "   Current permissions won't allow creating Spaces.\n",
            "\n",
            "üîß FIX:\n",
            "   1. Go to: https://huggingface.co/settings/tokens\n",
            "   2. Delete this token or create a NEW token\n",
            "   3. When creating, ensure you select:\n",
            "      ‚òëÔ∏è  'Write access to repos'  OR\n",
            "      ‚òëÔ∏è  'Make repo' permission\n",
            "   4. Copy the new token\n",
            "   5. Re-run Cell 3 and paste the NEW token\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "#@title üîç Check Fine-Grained Token Permissions (Detailed)\n",
        "import os\n",
        "from huggingface_hub import HfApi\n",
        "\n",
        "token = os.environ.get(\"HF_TOKEN\")\n",
        "if not token:\n",
        "    print(\"‚ùå HF_TOKEN not set!\")\n",
        "else:\n",
        "    try:\n",
        "        api = HfApi(token=token)\n",
        "        user_info = api.whoami()\n",
        "        \n",
        "        print(\"=\" * 70)\n",
        "        print(\"HUGGING FACE TOKEN INFORMATION\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"Username: {user_info['name']}\")\n",
        "        print(f\"Token type: {user_info.get('auth', {}).get('type', 'Unknown')}\")\n",
        "        \n",
        "        # For fine-grained tokens, check permissions\n",
        "        auth_info = user_info.get('auth', {})\n",
        "        access_token = auth_info.get('accessToken', {})\n",
        "        \n",
        "        print(f\"\\nToken role: {access_token.get('role', 'N/A')}\")\n",
        "        \n",
        "        # Check if repo.write permission exists\n",
        "        permissions = access_token.get('permissions', {})\n",
        "        print(f\"\\nPermissions:\")\n",
        "        for key, value in permissions.items():\n",
        "            print(f\"  - {key}: {value}\")\n",
        "        \n",
        "        # Check if we can create repos/spaces\n",
        "        repo_write = permissions.get('repo.write', False) or permissions.get('repo', {}).get('write', False)\n",
        "        \n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        if repo_write or str(repo_write) == 'write':\n",
        "            print(\"‚úÖ SUCCESS: Token has WRITE permissions for repositories!\")\n",
        "            print(\"   You can create Spaces with this token.\")\n",
        "        else:\n",
        "            print(\"‚ùå ERROR: Token does NOT have WRITE permissions!\")\n",
        "            print(\"   Current permissions won't allow creating Spaces.\")\n",
        "            print(\"\\nüîß FIX:\")\n",
        "            print(\"   1. Go to: https://huggingface.co/settings/tokens\")\n",
        "            print(\"   2. Delete this token or create a NEW token\")\n",
        "            print(\"   3. When creating, ensure you select:\")\n",
        "            print(\"      ‚òëÔ∏è  'Write access to repos'  OR\")\n",
        "            print(\"      ‚òëÔ∏è  'Make repo' permission\")\n",
        "            print(\"   4. Copy the new token\")\n",
        "            print(\"   5. Re-run Cell 3 and paste the NEW token\")\n",
        "        print(\"=\" * 70)\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "7afe27a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7afe27a0",
        "outputId": "cc43fc5f-505b-49c5-e0ae-2ce6c66ce379"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "hint: Using 'master' as the name for the initial branch. This default branch name\n",
            "hint: is subject to change. To configure the initial branch name to use in all\n",
            "hint: of your new repositories, which will suppress this warning, call:\n",
            "hint: \n",
            "hint: \tgit config --global init.defaultBranch <name>\n",
            "hint: \n",
            "hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\n",
            "hint: 'development'. The just-created branch can be renamed via this command:\n",
            "hint: \n",
            "hint: \tgit branch -m <name>\n",
            "o change. To configure the initial branch name to use in all\n",
            "hint: of your new repositories, which will suppress this warning, call:\n",
            "hint: \n",
            "hint: \tgit config --global init.defaultBranch <name>\n",
            "hint: \n",
            "hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\n",
            "hint: 'development'. The just-created branch can be renamed via this command:\n",
            "hint: \n",
            "hint: \tgit branch -m <name>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /home/chakri/Documents/S-7/MLoPs/Mlops2025w-112201022/CLASS/Week-10/hf_space/.git/\n",
            "-10/hf_space/.git/\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "bash: line 37: warning: here-document at line 13 delimited by end-of-file (wanted `PY')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo URL: https://huggingface.co/spaces/Chakradharreddy3237/mlops_class10_project\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pushed to: https://huggingface.co/spaces/Chakradharreddy3237/mlops_class10_project\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "set -e\n",
        "# prepare local repo\n",
        "rm -rf hf_space || true\n",
        "mkdir hf_space\n",
        "cp app.py requirements.txt hf_space/\n",
        "cd hf_space\n",
        "\n",
        "git init\n",
        "git config user.email \"112201022@smail.iitpkd.ac.in\"\n",
        "git config user.name \"ChakradharReddy3237\"\n",
        "# git lfs install  # Commented out - not needed\n",
        "\n",
        "python - <<'PY'\n",
        "from huggingface_hub import HfApi, Repository\n",
        "import os, sys\n",
        "token = os.environ.get(\"HF_TOKEN\")\n",
        "user = os.environ.get(\"HF_USER\")\n",
        "space = os.environ.get(\"SPACE_NAME\")\n",
        "if not token or not user or not space:\n",
        "    print(\"HF_TOKEN, HF_USER or SPACE_NAME not set. Aborting.\")\n",
        "    sys.exit(1)\n",
        "api = HfApi(token=token)\n",
        "\n",
        "repo_id = f\"{user}/{space}\"\n",
        "repo_url = api.create_repo(repo_id=repo_id, repo_type=\"space\",\n",
        "            space_sdk=\"gradio\",\n",
        "            exist_ok=True)\n",
        "print(\"Repo URL:\", repo_url)\n",
        "\n",
        "api.upload_folder(\n",
        "    folder_path=\".\",\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"space\",\n",
        "    commit_message=\"Initial commit: CIFAR-100 Gradio app (no model)\"\n",
        ")\n",
        "\n",
        "print(\"Pushed to:\", repo_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53d14b31",
      "metadata": {},
      "source": [
        "## ‚úÖ Deployment Successful!\n",
        "\n",
        "Your Space has been created at: **https://huggingface.co/spaces/Chakradharreddy3237/mlops_class10_project**\n",
        "\n",
        "### Next: Configure Secrets\n",
        "\n",
        "The Space needs your W&B API key to download the model. Follow these steps:\n",
        "\n",
        "1. **Open Space Settings**: https://huggingface.co/spaces/Chakradharreddy3237/mlops_class10_project/settings\n",
        "\n",
        "2. **Click \"Repository secrets\"** in the left sidebar\n",
        "\n",
        "3. **Add these secrets:**\n",
        "   - **Name**: `WANDB_API_KEY`\n",
        "     - **Value**: Your W&B API key (same one you used in Cell 2)\n",
        "   \n",
        "   - **Name**: `WANDB_ARTIFACT`\n",
        "     - **Value**: `ir2023/cifar100-hf-demo/resnet18-cifar100:latest`\n",
        "\n",
        "4. **Click \"Save\"** for each secret\n",
        "\n",
        "5. **Wait for the Space to rebuild** (it will automatically restart)\n",
        "\n",
        "6. **Visit your Space**: https://huggingface.co/spaces/Chakradharreddy3237/mlops_class10_project\n",
        "\n",
        "7. **Test it**: Upload a CIFAR-100 image and check if predictions work!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "47c4d391",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "YOUR W&B API KEY (copy this to Space secrets):\n",
            "======================================================================\n",
            "fbd5089fe8ff8a2f6dfc053ad7ac625ab10a7a2f\n",
            "======================================================================\n",
            "\n",
            "‚úÖ Copy the key above\n",
            "\n",
            "üìå Now open Space settings:\n",
            "   https://huggingface.co/spaces/Chakradharreddy3237/mlops_class10_project/settings\n",
            "\n",
            "üîß Steps:\n",
            "   1. Click 'Repository secrets' in left sidebar\n",
            "   2. Add secret: WANDB_API_KEY = <paste key above>\n",
            "   3. Add secret: WANDB_ARTIFACT = ir2023/cifar100-hf-demo/resnet18-cifar100:latest\n",
            "   4. Save and wait for Space to rebuild\n",
            "   5. Visit: https://huggingface.co/spaces/Chakradharreddy3237/mlops_class10_project\n"
          ]
        }
      ],
      "source": [
        "#@title üìã Get W&B API Key (for copying to Space secrets)\n",
        "import os\n",
        "import webbrowser\n",
        "\n",
        "wandb_key = os.environ.get('WANDB_API_KEY')\n",
        "if wandb_key:\n",
        "    print(\"=\" * 70)\n",
        "    print(\"YOUR W&B API KEY (copy this to Space secrets):\")\n",
        "    print(\"=\" * 70)\n",
        "    print(wandb_key)\n",
        "    print(\"=\" * 70)\n",
        "    print(\"\\n‚úÖ Copy the key above\")\n",
        "    print(\"\\nüìå Now open Space settings:\")\n",
        "    print(\"   https://huggingface.co/spaces/Chakradharreddy3237/mlops_class10_project/settings\")\n",
        "    print(\"\\nüîß Steps:\")\n",
        "    print(\"   1. Click 'Repository secrets' in left sidebar\")\n",
        "    print(\"   2. Add secret: WANDB_API_KEY = <paste key above>\")\n",
        "    print(\"   3. Add secret: WANDB_ARTIFACT = ir2023/cifar100-hf-demo/resnet18-cifar100:latest\")\n",
        "    print(\"   4. Save and wait for Space to rebuild\")\n",
        "    print(\"   5. Visit: https://huggingface.co/spaces/Chakradharreddy3237/mlops_class10_project\")\n",
        "else:\n",
        "    print(\"‚ùå W&B API key not found. Re-run Cell 2 to set it.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a5b107f",
      "metadata": {
        "id": "0a5b107f"
      },
      "source": [
        "## 10) Adding W&B API key as a secret in the Hugging Face Space\n",
        "\n",
        "After pushing the Space, do:\n",
        "1. Visit `https://huggingface.co/spaces/<HF_USER>/<SPACE_NAME>`.\n",
        "2. Click **Settings ‚Üí Secrets**.\n",
        "3. Add a secret named `WANDB_API_KEY` and paste your W&B API key (keep secret).\n",
        "4. Optionally set `WANDB_ARTIFACT` to the artifact path, e.g. `your_wandb_entity/cifar100-hf-demo/resnet18-cifar100:latest`.\n",
        "5. Rebuild the Space (there's a \"Rebuild\" button) so the app can download the artifact at startup.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e7cde70",
      "metadata": {
        "id": "6e7cde70"
      },
      "source": [
        "## 11) Test the deployed Space\n",
        "Open the Space URL `https://huggingface.co/spaces/<HF_USER>/<SPACE_NAME>`.\n",
        "- Check the Space logs (Settings ‚Üí Logs) if the model download or runtime fails.\n",
        "- Common issues: missing secret, wrong artifact name, package install errors (pin versions in requirements.txt).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b323968",
      "metadata": {
        "id": "0b323968"
      },
      "source": [
        "## 12) Instructor tips and cleanup\n",
        "- Keep epochs small during demos.\n",
        "- Instructor can host one shared Space and W&B project to avoid per-student pushes.\n",
        "- After course, remove the Space or set it to private if not needed.\n",
        "- Revoke tokens if accidentally exposed: Hugging Face (Settings ‚Üí Access Tokens), W&B (Settings ‚Üí API Keys).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "887da7d4",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "chicken (3.12.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
